<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Extending Lasso Model Fitting to Big Data — biglasso-package • biglasso</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Extending Lasso Model Fitting to Big Data — biglasso-package"><meta property="og:description" content="Extend lasso and elastic-net linear, logistic and cox regression models for
ultrahigh-dimensional, multi-gigabyte data sets that cannot be loaded into
available RAM. This package utilizes memory-mapped files to store the
massive data on the disk and only read those into memory whenever necessary
during model fitting. Moreover, some advanced feature screening rules are
proposed and implemented to accelerate the model fitting. As a result, this
package is much more memory- and computation-efficient and highly scalable
as compared to existing lasso-fitting packages such as
glmnet and
ncvreg, thus allowing for
powerful big data analysis even with only an ordinary laptop."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">biglasso</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.5.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../articles/biglasso.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/YaohuiZeng/biglasso/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Extending Lasso Model Fitting to Big Data</h1>
    <small class="dont-index">Source: <a href="https://github.com/YaohuiZeng/biglasso/blob/HEAD/R/biglasso-package.R" class="external-link"><code>R/biglasso-package.R</code></a></small>
    <div class="hidden name"><code>biglasso-package.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Extend lasso and elastic-net linear, logistic and cox regression models for
ultrahigh-dimensional, multi-gigabyte data sets that cannot be loaded into
available RAM. This package utilizes memory-mapped files to store the
massive data on the disk and only read those into memory whenever necessary
during model fitting. Moreover, some advanced feature screening rules are
proposed and implemented to accelerate the model fitting. As a result, this
package is much more memory- and computation-efficient and highly scalable
as compared to existing lasso-fitting packages such as
<a href="https://CRAN.R-project.org/package=glmnet" class="external-link">glmnet</a> and
<a href="https://CRAN.R-project.org/package=ncvreg" class="external-link">ncvreg</a>, thus allowing for
powerful big data analysis even with only an ordinary laptop.</p>
    </div>


    <div id="details">
    <h2>Details</h2>
    
<table class="table table"><tr><td>Package:</td><td>biglasso</td></tr><tr><td>Type:</td><td>Package</td></tr><tr><td>Version:</td><td>1.4-1</td></tr><tr><td>Date:</td><td>2021-01-29</td></tr><tr><td>License:</td><td>GPL-3</td></tr></table><p>Penalized regression models, in particular the lasso, have been extensively
applied to analyzing high-dimensional data sets. However, due to the memory
limit, existing R packages are not capable of fitting lasso models for
ultrahigh-dimensional, multi-gigabyte data sets which have been increasingly
seen in many areas such as genetics, biomedical imaging, genome sequencing
and high-frequency finance.</p>
<p>This package aims to fill the gap by extending lasso model fitting to Big
Data in R. Version &gt;= 1.2-3 represents a major redesign where the source
code is converted into C++ (previously in C), and new feature screening
rules, as well as OpenMP parallel computing, are implemented. Some key
features of <code>biglasso</code> are summarized as below:</p><ol><li><p>it
utilizes memory-mapped files to store the massive data on the disk, only
loading data into memory when necessary during model fitting. Consequently,
it's able to seamlessly data-larger-than-RAM cases.</p></li>
<li><p>it is built upon
pathwise coordinate descent algorithm with warm start, active set cycling,
and feature screening strategies, which has been proven to be one of fastest
lasso solvers.</p></li>
<li><p>in incorporates our newly developed hybrid and adaptive
screening that outperform state-of-the-art screening rules such as
the sequential strong rule (SSR) and the sequential EDPP rule (SEDPP) with
additional 1.5x to 4x speedup.</p></li>
<li><p>the implementation is designed to be as
memory-efficient as possible by eliminating extra copies of the data created
by other R packages, making it at least 2x more memory-efficient than
<code>glmnet</code>.</p></li>
<li><p>the underlying computation is implemented in C++, and
parallel computing with OpenMP is also supported.</p></li>
</ol><p><strong>For more information:</strong></p><ul><li><p>Benchmarking results:
<a href="https://github.com/YaohuiZeng/biglasso" class="external-link">https://github.com/YaohuiZeng/biglasso</a>.</p></li>
<li><p>Tutorial:
<a href="http://yaohuizeng.github.io/biglasso/articles/biglasso.html" class="external-link">http://yaohuizeng.github.io/biglasso/articles/biglasso.html</a></p></li>
<li><p>Technical paper:
<a href="https://arxiv.org/abs/1701.05936" class="external-link">https://arxiv.org/abs/1701.05936</a></p></li>
</ul></div>
    <div id="note">
    <h2>Note</h2>
    <p>The input design matrix X must be a <code><a href="https://rdrr.io/pkg/bigmemory/man/big.matrix.html" class="external-link">big.matrix</a></code> object. 
This can be created by the function <code>as.big.matrix</code> in the R package 
<a href="https://CRAN.R-project.org//package=bigmemory" class="external-link">bigmemory</a>. 
If the data (design matrix) is very large (e.g. 10 GB) and stored in an external 
file, which is often the case for big data, X can be created by calling the
function <code><a href="setupX.html">setupX</a></code>.
<strong>In this case, there are several restrictions about the data file:</strong></p><ol><li><p>the data file must be a well-formated ASCII-file, with
each row corresponding to an observation and each column a variable;</p></li>
<li><p>the data file must contain only one single type. Current version only
supports <code>double</code> type;</p></li>
<li><p>the data file must contain only numeric
variables. If there are categorical variables, the user needs to create
dummy variables for each categorical varable (by adding additional columns).</p></li>
</ol><p>Future versions will try to address these restrictions.</p>
<p>Denote the number of observations and variables be, respectively, <code>n</code>
and <code>p</code>. It's worth noting that the package is more suitable for wide
data (ultrahigh-dimensional, <code>p &gt;&gt; n</code>) as compared to long data
(<code>n &gt;&gt; p</code>). This is because the model fitting algorithm takes advantage
of sparsity assumption of high-dimensional data. To just give the user some
ideas, below are some benchmarking results of the total computing time (in
seconds) for solving lasso-penalized linear regression along a sequence of
100 values of the tuning parameter. In all cases, assume 20 non-zero
coefficients equal +/- 2 in the true model. (Based on Version 1.2-3,
screening rule "SSR-BEDPP" is used)</p><ul><li><p>For wide data case (<code>p &gt; n</code>), <code>n = 1,000</code>:</p><table class="table table"><tr><td><code>p</code></td><td>1,000</td><td>10,000</td><td>100,000</td><td>1,000,000</td></tr><tr><td>Size of <code>X</code></td><td>9.5 MB</td><td>95 MB</td><td>950 MB</td><td>9.5 GB</td></tr><tr><td>Elapsed time (s)</td><td>0.11</td><td>0.83</td><td>8.47</td><td>85.50</td></tr></table><p><!-- %\item For long data case (\code{n &gt;&gt; p}), \code{p = 1,000}:  -->
<!-- %\tabular{ccccc}{ -->
<!-- %\code{n} \tab 1,000 \tab 10,000 \tab 100,000 \tab 1,000,000 \cr  -->
<!-- %Size of \code{X} \tab 9.5 MB \tab 95 MB \tab 950 MB \tab 9.5 GB \cr  -->
<!-- %Elapsed time (s) \tab 2.50 \tab 11.43 \tab 83.69 \tab 1090.62 \cr %}  --></p></li>
</ul></div>
    <div id="references">
    <h2>References</h2>
    
<ul><li><p>Zeng, Y., and Breheny, P. (2017). The biglasso
Package: A Memory- and Computation-Efficient Solver for Lasso Model Fitting
with Big Data in R. <a href="https://arxiv.org/abs/1701.05936" class="external-link">https://arxiv.org/abs/1701.05936</a>.</p></li>
<li><p>Tibshirani, R., Bien, J., Friedman, J., Hastie, T., Simon, N., Taylor, J.,
and Tibshirani, R. J. (2012). Strong rules for discarding predictors in
lasso-type problems. <em>Journal of the Royal Statistical Society: Series
B (Statistical Methodology)</em>, <strong>74</strong>(2), 245-266.</p></li>
<li><p>Wang, J.,
Zhou, J., Wonka, P., and Ye, J. (2013). Lasso screening rules via dual
polytope projection. <em>In Advances in Neural Information Processing
Systems</em>, pp. 1070-1078.</p></li>
<li><p>Xiang, Z. J., and Ramadge, P. J. (2012).
Fast lasso screening tests based on correlations. <em>In Acoustics, Speech
and Signal Processing (ICASSP), 2012 IEEE International Conference on</em> (pp.
2137-2140). IEEE.</p></li>
<li><p>Wang, J., Zhou, J., Liu, J., Wonka, P., and Ye, J.
(2014). A safe screening rule for sparse logistic regression. <em>In
Advances in Neural Information Processing Systems</em>, pp. 1053-1061.</p></li>
</ul></div>
    <div id="author">
    <h2>Author</h2>
    <p>Yaohui Zeng, Chuyi Wang and Patrick Breheny</p>
<p>Maintainer: Yaohui Zeng &lt;yaohui.zeng@gmail.com&gt; and Chuyi Wang &lt;wwaa0208@gmail.com&gt;</p>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span></span>
<span class="r-in"><span class="co">## Example of reading data from external big data file, fit lasso model, </span></span>
<span class="r-in"><span class="co">## and run cross validation in parallel</span></span>
<span class="r-in"></span>
<span class="r-in"><span class="co"># simulated design matrix, 1000 observations, 500,000 variables, ~ 5GB</span></span>
<span class="r-in"><span class="co"># there are 10 true variables with non-zero coefficient 2.</span></span>
<span class="r-in"><span class="va">xfname</span> <span class="op">&lt;-</span> <span class="st">'x_e3_5e5.txt'</span> </span>
<span class="r-in"><span class="va">yfname</span> <span class="op">&lt;-</span> <span class="st">'y_e3_5e5.txt'</span> <span class="co"># response vector</span></span>
<span class="r-in"><span class="va">time</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.time.html" class="external-link">system.time</a></span><span class="op">(</span></span>
<span class="r-in">  <span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="setupX.html">setupX</a></span><span class="op">(</span><span class="va">xfname</span>, sep <span class="op">=</span> <span class="st">'\t'</span><span class="op">)</span> <span class="co"># create backing files (.bin, .desc)</span></span>
<span class="r-in"><span class="op">)</span></span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">time</span><span class="op">)</span> <span class="co"># ~ 7 minutes; this is just one-time operation</span></span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span></span>
<span class="r-in"></span>
<span class="r-in"><span class="co"># the big.matrix then can be retrieved by its descriptor file (.desc) in any new R session. </span></span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/base/rm.html" class="external-link">rm</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span></span>
<span class="r-in"><span class="va">xdesc</span> <span class="op">&lt;-</span> <span class="st">'x_e3_5e5.desc'</span> </span>
<span class="r-in"><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu">attach.big.matrix</span><span class="op">(</span><span class="va">xdesc</span><span class="op">)</span></span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span></span>
<span class="r-in"></span>
<span class="r-in"><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/read.table.html" class="external-link">read.table</a></span><span class="op">(</span><span class="va">yfname</span>, header <span class="op">=</span> <span class="cn">F</span><span class="op">)</span><span class="op">)</span></span>
<span class="r-in"><span class="va">time.fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.time.html" class="external-link">system.time</a></span><span class="op">(</span></span>
<span class="r-in">  <span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="biglasso.html">biglasso</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">'gaussian'</span>, screen <span class="op">=</span> <span class="st">'Hybrid'</span><span class="op">)</span></span>
<span class="r-in"><span class="op">)</span></span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">time.fit</span><span class="op">)</span> <span class="co"># ~ 44 seconds for fitting a lasso model along the entire solution path</span></span>
<span class="r-in"></span>
<span class="r-in"><span class="co"># cross validation in parallel</span></span>
<span class="r-in"><span class="va">seed</span> <span class="op">&lt;-</span> <span class="fl">1234</span></span>
<span class="r-in"><span class="va">time.cvfit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.time.html" class="external-link">system.time</a></span><span class="op">(</span></span>
<span class="r-in">  <span class="va">cvfit</span> <span class="op">&lt;-</span> <span class="fu"><a href="cv.biglasso.html">cv.biglasso</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">'gaussian'</span>, screen <span class="op">=</span> <span class="st">'Hybrid'</span>, </span>
<span class="r-in">                       seed <span class="op">=</span> <span class="va">seed</span>, ncores <span class="op">=</span> <span class="fl">4</span>, nfolds <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span class="r-in"><span class="op">)</span></span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">time.cvfit</span><span class="op">)</span> <span class="co"># ~ 3 minutes for 10-fold cross validation</span></span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">)</span></span>
<span class="r-in"><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">)</span></span>
<span class="r-in"><span class="op">}</span></span>
<span class="r-in"></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Yaohui Zeng, Chuyi Wang, Patrick Breheny.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.2.</p>
</div>

      </footer></div>

  


  

  </body></html>

